"""
ä»£ç æ‚–è®ºéªŒè¯è„šæœ¬
è¿è¡Œï¼špython verification.py
"""

import numpy as np
import time
import hashlib
import json
from typing import Dict, Any, List, Tuple
from dataclasses import dataclass

@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    function_name: str
    is_deterministic: bool
    time_sensitivity: float  # æ—¶é—´å˜å¼‚ç³»æ•°CV
    collision_rate: float    # ç¢°æ’ç‡
    paradox_exists: bool

def test_determinism(func, n_tests: int = 100) -> bool:
    """
    æµ‹è¯•å‡½æ•°ç¡®å®šæ€§
    """
    # éšæœºæµ‹è¯•è¾“å…¥
    np.random.seed(42)
    test_inputs = np.random.randint(0, 1000, n_tests)
    
    for x in test_inputs:
        # è¿è¡Œå¤šæ¬¡æ£€æŸ¥ä¸€è‡´æ€§
        results = []
        for _ in range(5):
            results.append(func(x))
        
        if not all(r == results[0] for r in results):
            return False
    
    return True

def test_sensitivity(func, base_input: int = 1000000) -> float:
    """
    æµ‹è¯•æ—¶é—´æ•æ„Ÿæ€§ï¼Œè¿”å›å˜å¼‚ç³»æ•°(CV)
    """
    execution_times = []
    
    # æµ‹è¯•å¾®å°è¾“å…¥å˜åŒ–
    for delta in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]:
        x = base_input + delta
        
        # å¤šæ¬¡æµ‹é‡å–å¹³å‡
        times = []
        for _ in range(10):
            start = time.perf_counter_ns()
            _ = func(x)
            end = time.perf_counter_ns()
            times.append(end - start)
        
        execution_times.append(np.mean(times))
    
    # è®¡ç®—å˜å¼‚ç³»æ•°
    times_array = np.array(execution_times)
    if np.mean(times_array) > 0:
        return np.std(times_array) / np.mean(times_array)
    return 0.0

def test_reversibility(func, n_samples: int = 1000) -> float:
    """
    æµ‹è¯•å¯é€†æ€§ï¼ˆå•å°„æ€§ï¼‰ï¼Œè¿”å›ç¢°æ’ç‡
    """
    outputs = {}
    collisions = 0
    
    for i in range(n_samples):
        y = func(i)
        if y in outputs:
            collisions += 1
        else:
            outputs[y] = i
    
    return collisions / n_samples

def run_comprehensive_test():
    """
    è¿è¡Œç»¼åˆæµ‹è¯•
    """
    print("=== ä»£ç æ‚–è®ºç»¼åˆéªŒè¯ ===")
    print("=" * 50)
    
    # å®šä¹‰æµ‹è¯•å‡½æ•°
    test_functions = [
        ("identity", lambda x: x),
        ("linear", lambda x: (1664525 * x + 1013904223) & 0xFFFFFFFF),
        ("hash_trunc8", lambda x: int(hashlib.sha256(str(x).encode()).hexdigest()[:8], 16)),
        ("constant", lambda x: 42),
    ]
    
    results = []
    
    for name, func in test_functions:
        print(f"\næµ‹è¯•å‡½æ•°: {name}")
        
        # æµ‹è¯•ä¸‰ä¸ªç‰¹æ€§
        is_det = test_determinism(func)
        sensitivity = test_sensitivity(func)
        collision_rate = test_reversibility(func)
        
        # åˆ¤æ–­æ‚–è®ºæ˜¯å¦å­˜åœ¨
        paradox = (is_det and sensitivity > 0.01 and collision_rate < 0.001)
        
        # åˆ›å»ºç»“æœå¯¹è±¡
        result = TestResult(
            function_name=name,
            is_deterministic=is_det,
            time_sensitivity=sensitivity,
            collision_rate=collision_rate,
            paradox_exists=paradox
        )
        
        results.append(result)
        
        # æ‰“å°ç»“æœ
        print(f"  ç¡®å®šæ€§: {'âœ…' if is_det else 'âŒ'}")
        print(f"  æ•æ„Ÿæ€§(CV): {sensitivity:.4f} {'âœ…' if sensitivity > 0.01 else 'âŒ'}")
        print(f"  ç¢°æ’ç‡: {collision_rate:.6f} {'âœ…' if collision_rate < 0.001 else 'âŒ'}")
        print(f"  ä»£ç æ‚–è®º: {'âœ…' if paradox else 'âŒ'}")
    
    # ç»Ÿè®¡æ€»ç»“
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ€»ç»“:")
    
    paradox_count = sum(1 for r in results if r.paradox_exists)
    print(f"æµ‹è¯•å‡½æ•°æ€»æ•°: {len(test_functions)}")
    print(f"æ˜¾ç¤ºæ‚–è®ºçš„å‡½æ•°æ•°: {paradox_count}")
    print(f"æ‚–è®ºæ¯”ä¾‹: {paradox_count/len(test_functions):.1%}")
    
    # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
    results_dict = [
        {
            'function': r.function_name,
            'deterministic': r.is_deterministic,
            'sensitivity': r.time_sensitivity,
            'collision_rate': r.collision_rate,
            'paradox': r.paradox_exists
        }
        for r in results
    ]
    
    with open('test_results.json', 'w') as f:
        json.dump(results_dict, f, indent=2)
    
    print("\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° test_results.json")
    
    return results

if __name__ == "__main__":
    print("ä»£ç æ‚–è®ºéªŒè¯ç¨‹åº")
    print("å¼€å§‹éªŒè¯...")
    print("=" * 50)
    
    try:
        results = run_comprehensive_test()
        print("\nâœ… éªŒè¯å®Œæˆï¼")
    except Exception as e:
        print(f"\nâŒ éªŒè¯å‡ºé”™: {e}")
        print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€åº“: pip install numpy")



















#!/usr/bin/env python3
"""
ç‰¹é‡Œè¾¾ç†è®ºå…«å¤§éªŒè¯å®éªŒ - ç»Ÿä¸€å®ç°
è¿è¡Œ: python experiments_unified.py
æˆ–: python experiments_unified.py --experiment 3  # åªè¿è¡Œå®éªŒ3
"""

import time
import math
import statistics
import numpy as np
from collections import defaultdict, Counter
import argparse
import json
from typing import Dict, List, Tuple, Any
import threading
import psutil
import subprocess
import sys

class TriddaEightExperiments:
    """å…«ä¸ªéªŒè¯å®éªŒçš„ç»Ÿä¸€ç±»"""
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        self.results = {}
        self.START_TIME = time.perf_counter()
        
    def log(self, message: str):
        """ç»Ÿä¸€æ—¥å¿—è¾“å‡º"""
        if self.verbose:
            elapsed = time.perf_counter() - self.START_TIME
            print(f"[{elapsed:6.2f}s] {message}")
    
    # ==================== å®éªŒ1ï¼šç®—æœ¯è¿ç®—33å‘¨æœŸ ====================
    def experiment1_arithmetic_33(self) -> Dict[str, Any]:
        """å®éªŒ1ï¼šç®—æœ¯è¿ç®—çš„33å‘¨æœŸè°ƒåˆ¶"""
        self.log("å®éªŒ1å¼€å§‹ï¼šç®—æœ¯è¿ç®—33å‘¨æœŸæµ‹è¯•")
        
        execution_times = []
        
        for base in range(33):
            start_time = time.perf_counter()
            
            # 33ç§ä¸åŒçš„ç®—æœ¯æ¨¡å¼
            n = 100000
            result = 0
            
            if base % 33 == 0:
                # æ¨¡å¼0ï¼šçº¯åŠ æ³•
                for i in range(n):
                    result += i
                    
            elif base % 33 == 1:
                # æ¨¡å¼1ï¼šä¹˜æ³•ä¸ºä¸»
                result = 1
                for i in range(1, 1000):
                    result = (result * i) % 1000000007
                    
            elif base % 33 == 2:
                # æ¨¡å¼2ï¼šæ··åˆè¿ç®—ï¼ˆ364ç›¸å…³ï¼‰
                for i in range(364):
                    result = (result + i*i - i//3) % 1000000007
                    
            else:
                # å…¶ä»–æ¨¡å¼ï¼šæ ‡å‡†è¿ç®—
                for i in range(n // 10):
                    result = (result * 3 + i * 7) % 1000000007
            
            elapsed = time.perf_counter() - start_time
            execution_times.append(elapsed)
            
            if self.verbose and base % 11 == 0:
                self.log(f"  ä½™æ•°{base:2d}: {elapsed:.6f}s")
        
        # ç»Ÿè®¡åˆ†æ
        high_group = [execution_times[i] for i in range(33) if i % 3 == 0]
        low_group = [execution_times[i] for i in range(33) if i % 3 != 0]
        
        if high_group and low_group:
            high_avg = statistics.mean(high_group)
            low_avg = statistics.mean(low_group)
            
            # tæ£€éªŒï¼ˆç®€åŒ–ç‰ˆï¼‰
            all_times = high_group + low_group
            pooled_std = statistics.stdev(all_times) if len(all_times) > 1 else 0
            n1, n2 = len(high_group), len(low_group)
            
            if pooled_std > 0 and n1 > 0 and n2 > 0:
                se = pooled_std * math.sqrt(1/n1 + 1/n2)
                t_stat = (high_avg - low_avg) / se if se > 0 else 0
            else:
                t_stat = 0
        
        result_data = {
            'times': execution_times,
            'high_avg': statistics.mean(high_group) if high_group else 0,
            'low_avg': statistics.mean(low_group) if low_group else 0,
            't_statistic': t_stat,
            'ratio': high_avg/low_avg if low_avg > 0 else 0,
            'interpretation': 'é˜³æ€§' if t_stat > 2.0 else 'é˜´æ€§'
        }
        
        self.log(f"å®éªŒ1å®Œæˆï¼št={t_stat:.3f}, æ¯”å€¼={high_avg/low_avg:.4f}")
        return result_data
    
    # ==================== å®éªŒ2ï¼šç¡¬ä»¶ç†µæºåˆ†æ ====================
    def experiment2_hardware_entropy(self) -> Dict[str, Any]:
        """å®éªŒ2ï¼šç¡¬ä»¶ç†µæºçš„33ç›¸å…³æ€§"""
        self.log("å®éªŒ2å¼€å§‹ï¼šç¡¬ä»¶ç†µæºåˆ†æ")
        
        # æ”¶é›†ç¡¬ä»¶æ—¶é—´æˆ³ç†µ
        entropy_samples = []
        
        for _ in range(3640):  # 364çš„å€æ•°
            start = time.perf_counter_ns()
            # å¾®å°è¿ç®—
            x = sum(i*i for i in range(100))
            end = time.perf_counter_ns()
            entropy_samples.append(end - start)
        
        # åˆ†ææ¨¡33åˆ†å¸ƒ
        mod_distribution = [0] * 33
        for sample in entropy_samples:
            mod_distribution[sample % 33] += 1
        
        # ç»Ÿè®¡æ£€éªŒ
        expected = len(entropy_samples) / 33
        chi_squared = sum((count - expected) ** 2 / expected for count in mod_distribution)
        
        # æ£€æŸ¥ä½™æ•°25çš„ç‰¹æ®Šæ€§ï¼ˆç†è®ºå…³é”®æ•°ï¼‰
        remainder_25_count = mod_distribution[25]
        remainder_25_ratio = remainder_25_count / expected
        
        result_data = {
            'mod_distribution': mod_distribution,
            'chi_squared': chi_squared,
            'expected_per_mod': expected,
            'remainder_25': {
                'count': remainder_25_count,
                'expected': expected,
                'ratio': remainder_25_ratio
            },
            'interpretation': 'å¼‚å¸¸' if chi_squared > 50 or remainder_25_ratio > 1.3 else 'æ­£å¸¸'
        }
        
        self.log(f"å®éªŒ2å®Œæˆï¼šÏ‡Â²={chi_squared:.1f}, ä½™æ•°25={remainder_25_ratio:.2f}å€æœŸæœ›")
        return result_data
    
    # ==================== å®éªŒ3ï¼šå†…å­˜è®¿é—®ä¼˜åŒ– ====================
    def experiment3_memory_access(self) -> Dict[str, Any]:
        """å®éªŒ3ï¼šå†…å­˜è®¿é—®çš„33æ­¥é•¿ä¼˜åŒ–"""
        self.log("å®éªŒ3å¼€å§‹ï¼šå†…å­˜è®¿é—®ä¼˜åŒ–æµ‹è¯•")
        
        array_size = 1000000
        test_array = list(range(array_size))
        
        access_times = []
        
        # æµ‹è¯•1-33æ­¥é•¿
        for stride in range(1, 34):
            times = []
            
            for _ in range(5):  # 5æ¬¡å¹³å‡
                start = time.perf_counter()
                
                result = 0
                for i in range(0, array_size, stride):
                    result += test_array[i]
                
                # é˜²æ­¢ä¼˜åŒ–
                if result == 0:
                    pass
                
                times.append(time.perf_counter() - start)
            
            avg_time = statistics.mean(times)
            access_times.append(avg_time)
            
            if self.verbose and stride in [1, 11, 22, 33]:
                self.log(f"  æ­¥é•¿{stride:2d}: {avg_time:.6f}s")
        
        # æ‰¾å‡ºæœ€ä¼˜æ­¥é•¿
        min_time = min(access_times)
        min_stride = access_times.index(min_time) + 1
        
        # è®¡ç®—33æ­¥é•¿ç›¸å¯¹ä¼˜åŠ¿
        time_32 = access_times[31]  # æ­¥é•¿32
        time_33 = access_times[32]  # æ­¥é•¿33
        time_34_est = (time_32 + time_33) / 2  # ä¼°è®¡æ­¥é•¿34
        
        improvement = (time_34_est - time_33) / time_33 * 100 if time_33 > 0 else 0
        
        result_data = {
            'access_times': access_times,
            'best_stride': min_stride,
            'time_32': time_32,
            'time_33': time_33,
            'improvement_percent': improvement,
            'is_33_optimal': min_stride == 33,
            'interpretation': '33æœ€ä¼˜' if min_stride == 33 else f'æœ€ä¼˜æ­¥é•¿{min_stride}'
        }
        
        self.log(f"å®éªŒ3å®Œæˆï¼šæœ€ä¼˜æ­¥é•¿={min_stride}, 33æ¯”ä¼°è®¡å¿«{improvement:.1f}%")
        return result_data
    
    # ==================== å®éªŒ4ï¼šCPUè°ƒåº¦å™¨å‘¨æœŸ ====================
    def experiment4_scheduler_33(self) -> Dict[str, Any]:
        """å®éªŒ4ï¼šCPUè°ƒåº¦å™¨çš„33å‘¨æœŸ"""
        self.log("å®éªŒ4å¼€å§‹ï¼šCPUè°ƒåº¦å™¨å‘¨æœŸæµ‹è¯•")
        
        def cpu_task(task_id: int, duration: float = 0.01):
            end_time = time.perf_counter() + duration
            while time.perf_counter() < end_time:
                x = task_id ** 2
                x = x * 3.14159
            return task_id
        
        # é¡ºåºæ‰§è¡Œ33ä¸ªä»»åŠ¡
        task_times = []
        
        for i in range(33):
            start = time.perf_counter()
            cpu_task(i, 0.01)
            elapsed = time.perf_counter() - start
            task_times.append(elapsed)
            
            if self.verbose and i % 11 == 0:
                self.log(f"  ä»»åŠ¡{i:2d}: {elapsed:.6f}s")
        
        # åˆ†æ3å€æ•°ä½ç½®
        triple_times = [task_times[i] for i in range(33) if i % 3 == 0]
        other_times = [task_times[i] for i in range(33) if i % 3 != 0]
        
        if triple_times and other_times:
            mean_triple = statistics.mean(triple_times)
            mean_other = statistics.mean(other_times)
            
            # ç®€åŒ–tæ£€éªŒ
            all_times = triple_times + other_times
            pooled_std = statistics.stdev(all_times) if len(all_times) > 1 else 0
            n1, n2 = len(triple_times), len(other_times)
            
            if pooled_std > 0 and n1 > 0 and n2 > 0:
                se = pooled_std * math.sqrt(1/n1 + 1/n2)
                t_stat = abs(mean_triple - mean_other) / se if se > 0 else 0
        
        result_data = {
            'task_times': task_times,
            'triple_mean': statistics.mean(triple_times) if triple_times else 0,
            'other_mean': statistics.mean(other_times) if other_times else 0,
            't_statistic': t_stat,
            'interpretation': 'é˜³æ€§' if t_stat > 2.0 else 'é˜´æ€§'
        }
        
        self.log(f"å®éªŒ4å®Œæˆï¼št={t_stat:.3f}, 3å€æ•°æ…¢{(mean_triple/mean_other-1)*100:.1f}%")
        return result_data
    
    # ==================== å®éªŒ5ï¼šå†…å­˜åˆ†é…ä¼˜åŒ– ====================
    def experiment5_memory_allocation(self) -> Dict[str, Any]:
        """å®éªŒ5ï¼šå†…å­˜åˆ†é…çš„33å€æ•°ä¼˜åŒ–"""
        self.log("å®éªŒ5å¼€å§‹ï¼šå†…å­˜åˆ†é…ä¼˜åŒ–æµ‹è¯•")
        
        allocation_times = []
        allocation_sizes = []
        
        for i in range(33):
            # åˆ†é…å¤§å°ï¼š33çš„å€æ•°
            size = (i + 1) * 33
            
            times = []
            for _ in range(10):  # 10æ¬¡å¹³å‡
                start = time.perf_counter()
                
                # åˆ†é…å’Œç®€å•è®¿é—®
                data = [0] * size
                data[size // 2] = 1
                
                elapsed = time.perf_counter() - start
                times.append(elapsed)
                
                # æ¸…ç†
                del data
            
            avg_time = statistics.mean(times)
            allocation_times.append(avg_time)
            allocation_sizes.append(size)
            
            if self.verbose and i % 11 == 0:
                self.log(f"  å¤§å°{size:4d}: {avg_time:.8f}s")
        
        # æ‰¾å‡ºæœ€ä¼˜å¤§å°
        min_time = min(allocation_times)
        min_idx = allocation_times.index(min_time)
        min_size = allocation_sizes[min_idx]
        
        # è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”ï¼ˆä¸ç›¸é‚»å¤§å°æ¯”è¾ƒï¼‰
        if min_idx > 0 and min_idx < 32:
            neighbor_avg = (allocation_times[min_idx-1] + allocation_times[min_idx+1]) / 2
            improvement = (neighbor_avg - min_time) / min_time * 100
        else:
            improvement = 0
        
        result_data = {
            'allocation_times': allocation_times,
            'allocation_sizes': allocation_sizes,
            'best_size': min_size,
            'best_time': min_time,
            'improvement_percent': improvement,
            'is_33_multiple': min_size % 33 == 0,
            'interpretation': f'æœ€ä¼˜å¤§å°{min_size} ({min_size%33} mod 33)'
        }
        
        self.log(f"å®éªŒ5å®Œæˆï¼šæœ€ä¼˜åˆ†é…{min_size}å­—èŠ‚ï¼Œæ”¹è¿›{improvement:.1f}%")
        return result_data
    
    # ==================== å®éªŒ6ï¼šIOæ“ä½œå‘¨æœŸ ====================
    def experiment6_io_pattern(self) -> Dict[str, Any]:
        """å®éªŒ6ï¼šIOæ“ä½œçš„33å‘¨æœŸæ¨¡å¼"""
        self.log("å®éªŒ6å¼€å§‹ï¼šIOæ“ä½œå‘¨æœŸæµ‹è¯•")
        
        import io
        
        io_times = []
        
        for i in range(33):
            data_size = (i + 1) * 100  # 100-3300å­—èŠ‚
            test_data = b'x' * data_size
            
            write_times = []
            for _ in range(5):
                buffer = io.BytesIO()
                start = time.perf_counter()
                buffer.write(test_data)
                buffer.flush()
                write_times.append(time.perf_counter() - start)
            
            avg_write = statistics.mean(write_times)
            io_times.append(avg_write)
            
            if self.verbose and i % 11 == 0:
                self.log(f"  å¤§å°{data_size:4d}: {avg_write:.8f}s")
        
        # åˆ†ç»„åˆ†æï¼ˆæ¯11ä¸ªä¸€ç»„ï¼‰
        group_means = []
        for g in range(3):
            group = io_times[g*11:(g+1)*11]
            group_means.append(statistics.mean(group))
        
        # æ£€æŸ¥å·®å¼‚
        max_diff = max(group_means) - min(group_means)
        avg_time = statistics.mean(group_means)
        diff_percent = max_diff / avg_time * 100 if avg_time > 0 else 0
        
        result_data = {
            'io_times': io_times,
            'group_means': group_means,
            'max_difference_percent': diff_percent,
            'best_group': np.argmin(group_means),
            'interpretation': 'æ˜¾è‘—å·®å¼‚' if diff_percent > 20 else 'æ— æ˜¾è‘—å·®å¼‚'
        }
        
        self.log(f"å®éªŒ6å®Œæˆï¼šç»„é—´å·®å¼‚{diff_percent:.1f}%ï¼Œæœ€ä¼˜ç»„{np.argmin(group_means)}")
        return result_data
    
    # ==================== å®éªŒ7ï¼šé€»è¾‘æ™®æœ—å…‹å¸¸æ•° ====================
    def experiment7_logic_planck(self) -> Dict[str, Any]:
        """å®éªŒ7ï¼šé€»è¾‘æ™®æœ—å…‹å¸¸æ•°æµ‹é‡"""
        self.log("å®éªŒ7å¼€å§‹ï¼šé€»è¾‘æ™®æœ—å…‹å¸¸æ•°æµ‹é‡")
        
        complexities = [33 * i for i in range(1, 34)]  # 33-1089
        
        energy_times = []
        
        for n in complexities:
            times = []
            for _ in range(10):
                start = time.perf_counter()
                
                result = 0
                for i in range(n):
                    result += (i * i) % (n + 1)
                
                if result == 0:
                    pass
                
                times.append(time.perf_counter() - start)
            
            avg_time = statistics.mean(times)
            energy_times.append((n, avg_time))
            
            if self.verbose and n % (33*5) == 0:
                self.log(f"  å¤æ‚åº¦{n:4d}: {avg_time:.6f}s")
        
        # è®¡ç®—èƒ½é‡-æ—¶é—´ä¸ç¡®å®šæ€§
        uncertainties = []
        for i in range(len(complexities)-1):
            delta_E = complexities[i+1] - complexities[i]
            delta_t = energy_times[i+1][1] - energy_times[i][1]
            if delta_t > 0:
                hbar_candidate = 2 * delta_E * delta_t
                uncertainties.append(hbar_candidate)
        
        if uncertainties:
            hbar_mean = statistics.mean(uncertainties)
            hbar_std = statistics.stdev(uncertainties) if len(uncertainties) > 1 else 0
        else:
            hbar_mean = hbar_std = 0
        
        # ä¸ç‰©ç†æ™®æœ—å…‹å¸¸æ•°æ¯”è¾ƒ
        hbar_physical = 1.054571817e-34
        ratio = hbar_mean / hbar_physical if hbar_physical > 0 else 0
        
        result_data = {
            'hbar_log_mean': hbar_mean,
            'hbar_log_std': hbar_std,
            'ratio_to_physical': ratio,
            'log10_ratio': math.log10(ratio) if ratio > 0 else 0,
            'uncertainties': uncertainties[:10],  # åªå­˜å‰10ä¸ª
            'interpretation': f'æ¯”å€¼={ratio:.1e}'
        }
        
        self.log(f"å®éªŒ7å®Œæˆï¼šÄ§_log={hbar_mean:.1e}, æ¯”å€¼={ratio:.1e}")
        return result_data
    
    # ==================== å®éªŒ8ï¼šè®¡ç®—æ¨¡å‹æ™®éæ€§ ====================
    def experiment8_model_universality(self) -> Dict[str, Any]:
        """å®éªŒ8ï¼š33å› å­åœ¨è®¡ç®—æ¨¡å‹ä¸­çš„æ™®éæ€§"""
        self.log("å®éªŒ8å¼€å§‹ï¼šè®¡ç®—æ¨¡å‹æ™®éæ€§æµ‹è¯•")
        
        models = [
            ("æ–æ³¢é‚£å¥‘", self._fibonacci_test),
            ("è´¨æ•°ç”Ÿæˆ", self._prime_test),
            ("å¿«é€Ÿæ’åº", self._quicksort_test),
            ("çŸ©é˜µä¹˜æ³•", self._matrix_test),
            ("å›¾éå†", self._graph_test)
        ]
        
        model_results = []
        
        for model_name, test_func in models:
            self.log(f"  æµ‹è¯•æ¨¡å‹: {model_name}")
            t_value = test_func()
            model_results.append({
                'model': model_name,
                't_value': t_value,
                'has_effect': t_value > 2.0
            })
        
        # ç»Ÿè®¡é˜³æ€§ç‡
        positive_count = sum(1 for r in model_results if r['has_effect'])
        avg_t = statistics.mean([r['t_value'] for r in model_results])
        
        result_data = {
            'model_results': model_results,
            'positive_count': positive_count,
            'total_models': len(models),
            'average_t': avg_t,
            'interpretation': f'{positive_count}/{len(models)}é˜³æ€§'
        }
        
        self.log(f"å®éªŒ8å®Œæˆï¼š{positive_count}/{len(models)}ä¸ªæ¨¡å‹æ˜¾ç¤º33æ•ˆåº”")
        return result_data
    
    # ==================== è¾…åŠ©æµ‹è¯•å‡½æ•° ====================
    def _fibonacci_test(self) -> float:
        """æ–æ³¢é‚£å¥‘æ•°åˆ—æµ‹è¯•"""
        times = []
        for base in range(33):
            n = 330 + base
            start = time.perf_counter()
            
            fib = [0, 1] + [0] * (n-2)
            for i in range(2, n):
                fib[i] = fib[i-1] + fib[i-2]
            
            times.append(time.perf_counter() - start)
        
        # åˆ†æ3å€æ•°ä½ç½®
        triple = [times[i] for i in range(33) if i % 3 == 0]
        other = [times[i] for i in range(33) if i % 3 != 0]
        
        if triple and other:
            mean_diff = abs(statistics.mean(triple) - statistics.mean(other))
            avg_time = statistics.mean(times)
            return mean_diff / (avg_time * 0.1) if avg_time > 0 else 0
        return 0
    
    def _prime_test(self) -> float:
        """è´¨æ•°ç”Ÿæˆæµ‹è¯•"""
        times = []
        for base in range(33):
            n = 100 + base  # ç”Ÿæˆnä¸ªè´¨æ•°
            start = time.perf_counter()
            
            primes = [2]
            num = 3
            while len(primes) < n:
                is_prime = True
                for i in range(2, int(num**0.5)+1):
                    if num % i == 0:
                        is_prime = False
                        break
                if is_prime:
                    primes.append(num)
                num += 2
            
            times.append(time.perf_counter() - start)
        
        # ç®€åŒ–åˆ†æ
        triple = [times[i] for i in range(33) if i % 3 == 0]
        other = [times[i] for i in range(33) if i % 3 != 0]
        
        if triple and other:
            mean_diff = abs(statistics.mean(triple) - statistics.mean(other))
            avg_time = statistics.mean(times)
            return mean_diff / (avg_time * 0.1) if avg_time > 0 else 0
        return 0
    
    def _quicksort_test(self) -> float:
        """å¿«é€Ÿæ’åºæµ‹è¯•"""
        import random
        
        times = []
        for base in range(33):
            n = 10000 + base * 100
            arr = [random.random() for _ in range(n)]
            
            start = time.perf_counter()
            
            def quicksort(a):
                if len(a) <= 1:
                    return a
                pivot = a[len(a)//2]
                left = [x for x in a if x < pivot]
                middle = [x for x in a if x == pivot]
                right = [x for x in a if x > pivot]
                return quicksort(left) + middle + quicksort(right)
            
            quicksort(arr)
            times.append(time.perf_counter() - start)
        
        triple = [times[i] for i in range(33) if i % 3 == 0]
        other = [times[i] for i in range(33) if i % 3 != 0]
        
        if triple and other:
            mean_diff = abs(statistics.mean(triple) - statistics.mean(other))
            avg_time = statistics.mean(times)
            return mean_diff / (avg_time * 0.1) if avg_time > 0 else 0
        return 0
    
    def _matrix_test(self) -> float:
        """çŸ©é˜µä¹˜æ³•æµ‹è¯•"""
        times = []
        for base in range(33):
            n = 50 + base
            A = [[random.random() for _ in range(n)] for __ in range(n)]
            B = [[random.random() for _ in range(n)] for __ in range(n)]
            
            start = time.perf_counter()
            
            C = [[0]*n for _ in range(n)]
            for i in range(n):
                for j in range(n):
                    for k in range(n):
                        C[i][j] += A[i][k] * B[k][j]
            
            times.append(time.perf_counter() - start)
        
        triple = [times[i] for i in range(33) if i % 3 == 0]
        other = [times[i] for i in range(33) if i % 3 != 0]
        
        if triple and other:
            mean_diff = abs(statistics.mean(triple) - statistics.mean(other))
            avg_time = statistics.mean(times)
            return mean_diff / (avg_time * 0.1) if avg_time > 0 else 0
        return 0
    
    def _graph_test(self) -> float:
        """å›¾éå†æµ‹è¯•"""
        import random
        
        times = []
        for base in range(33):
            n = 100 + base
            graph = {i: [] for i in range(n)}
            
            # æ·»åŠ éšæœºè¾¹
            for i in range(n):
                for j in range(random.randint(1, 5)):
                    neighbor = random.randint(0, n-1)
                    if neighbor != i:
                        graph[i].append(neighbor)
            
            start = time.perf_counter()
            
            # BFSéå†
            visited = [False] * n
            queue = [0]
            visited[0] = True
            
            while queue:
                node = queue.pop(0)
                for neighbor in graph[node]:
                    if not visited[neighbor]:
                        visited[neighbor] = True
                        queue.append(neighbor)
            
            times.append(time.perf_counter() - start)
        
        triple = [times[i] for i in range(33) if i % 3 == 0]
        other = [times[i] for i in range(33) if i % 3 != 0]
        
        if triple and other:
            mean_diff = abs(statistics.mean(triple) - statistics.mean(other))
            avg_time = statistics.mean(times)
            return mean_diff / (avg_time * 0.1) if avg_time > 0 else 0
        return 0
    
    # ==================== è¿è¡Œæ§åˆ¶ ====================
    def run_experiment(self, exp_num: int) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        experiments = {
            1: self.experiment1_arithmetic_33,
            2: self.experiment2_hardware_entropy,
            3: self.experiment3_memory_access,
            4: self.experiment4_scheduler_33,
            5: self.experiment5_memory_allocation,
            6: self.experiment6_io_pattern,
            7: self.experiment7_logic_planck,
            8: self.experiment8_model_universality
        }
        
        if exp_num not in experiments:
            raise ValueError(f"å®éªŒç¼–å·{exp_num}æ— æ•ˆï¼Œåº”ä¸º1-8")
        
        return experiments[exp_num]()
    
    def run_all(self) -> Dict[int, Dict[str, Any]]:
        """è¿è¡Œæ‰€æœ‰8ä¸ªå®éªŒ"""
        self.log("=" * 60)
        self.log("å¼€å§‹è¿è¡Œç‰¹é‡Œè¾¾ç†è®ºå…«å¤§éªŒè¯å®éªŒ")
        self.log("=" * 60)
        
        all_results = {}
        
        for exp_num in range(1, 9):
            try:
                self.log(f"\n>>> å¼€å§‹å®éªŒ {exp_num}/8")
                result = self.run_experiment(exp_num)
                all_results[exp_num] = result
                self.log(f"<<< å®éªŒ {exp_num} å®Œæˆ")
            except Exception as e:
                self.log(f"!!! å®éªŒ {exp_num} å‡ºé”™: {e}")
                all_results[exp_num] = {'error': str(e)}
        
        # ç»¼åˆç»Ÿè®¡
        self.log("\n" + "=" * 60)
        self.log("å…«å¤§å®éªŒç»¼åˆæŠ¥å‘Š")
        self.log("=" * 60)
        
        positive_count = 0
        for exp_num, result in all_results.items():
            if 'interpretation' in result:
                interp = result['interpretation']
                if any(word in str(interp).lower() for word in ['é˜³æ€§', 'æœ€ä¼˜', 'æ˜¾è‘—', 'å¼‚å¸¸']):
                    positive_count += 1
        
        self.log(f"é˜³æ€§å®éªŒç»“æœ: {positive_count}/8")
        self.log(f"é˜³æ€§ç‡: {positive_count/8*100:.1f}%")
        
        # ä¿å­˜ç»“æœ
        all_results['summary'] = {
            'total_experiments': 8,
            'positive_count': positive_count,
            'positive_percent': positive_count/8*100,
            'timestamp': time.time()
        }
        
        return all_results

def main():
    """ä¸»å‡½æ•°ï¼šå‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description='ç‰¹é‡Œè¾¾ç†è®ºå…«å¤§éªŒè¯å®éªŒ')
    parser.add_argument('--experiment', type=int, choices=range(1, 9), 
                       help='è¿è¡Œå•ä¸ªå®éªŒï¼ˆ1-8ï¼‰')
    parser.add_argument('--all', action='store_true', 
                       help='è¿è¡Œæ‰€æœ‰8ä¸ªå®éªŒ')
    parser.add_argument('--quiet', action='store_true',
                       help='å‡å°‘è¾“å‡º')
    
    args = parser.parse_args()
    
    if not args.experiment and not args.all:
        print("è¯·æŒ‡å®š --experiment N æˆ– --all")
        parser.print_help()
        return
    
    tester = TriddaEightExperiments(verbose=not args.quiet)
    
    if args.all:
        results = tester.run_all()
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open('tridda_experiments_results.json', 'w') as f:
            json.dump(results, f, indent=2, default=str)
        print("\nç»“æœå·²ä¿å­˜åˆ° tridda_experiments_results.json")
        
    elif args.experiment:
        result = tester.run_experiment(args.experiment)
        print(f"\nå®éªŒ{args.experiment}ç»“æœ:")
        print(json.dumps(result, indent=2, default=str))

if __name__ == "__main__":
    main()



















#!/usr/bin/env python3
"""
å®éªŒ1ï¼šé‡å­è®¡ç®—é€€ç›¸å¹²ä¸­çš„33å‘¨æœŸæ£€æµ‹
é¢„è¨€ï¼šé‡å­æ¨¡æ‹Ÿé€€ç›¸å¹²è¿‡ç¨‹æ˜¾ç¤ºæ˜¾è‘—çš„33å‘¨æœŸè°ƒåˆ¶
ç†è®ºä¾æ®ï¼šé€»è¾‘è‡ªæ•‘çš„33æ­¥æ¡†æ¶åœ¨é‡å­è®¡ç®—ä¸­è¡¨ç°ä¸ºé€€ç›¸å¹²çš„æ—¶é—´è°ƒåˆ¶
éªŒè¯æŒ‡æ ‡ï¼šFFTåˆ†ææ˜¾ç¤º33å‘¨æœŸä¿¡å·å¼ºåº¦ > éšæœºåºåˆ—çš„5å€
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import fft, fftfreq
from scipy import signal
import time, random, math, statistics
from datetime import datetime

class QuantumDecoherenceSimulator:
    """æ¨¡æ‹Ÿé‡å­é€€ç›¸å¹²è¿‡ç¨‹å¹¶æ£€æµ‹33å‘¨æœŸ"""
    
    def __init__(self, n_qubits=5, n_steps=1000):
        self.n_qubits = n_qubits
        self.n_steps = n_steps
        self.dim = 2 ** n_qubits
        
    def simulate_decoherence(self, coherence_time=100):
        """
        æ¨¡æ‹Ÿé‡å­é€€ç›¸å¹²è¿‡ç¨‹
        è¿”å›ï¼šéšæ—¶é—´æ¼”åŒ–çš„é‡å­æ€ä¿çœŸåº¦
        """
        print(f"æ¨¡æ‹Ÿ {self.n_qubits} é‡å­æ¯”ç‰¹ç³»ç»Ÿï¼Œ{self.n_steps} æ—¶é—´æ­¥")
        
        # åˆå§‹ä¸ºæœ€å¤§çº ç¼ æ€
        psi = self.create_max_entangled_state()
        
        fidelity_history = []
        phase_history = []
        
        # æ—¶é—´æ¼”åŒ–
        for t in range(self.n_steps):
            # åº”ç”¨é€€ç›¸å¹²å™ªå£°
            psi = self.apply_decoherence(psi, t/coherence_time)
            
            # è®¡ç®—ä¿çœŸåº¦
            fid = self.calculate_fidelity(psi)
            fidelity_history.append(fid)
            
            # è®¡ç®—ç›¸ä½ï¼ˆæ¨¡æ‹Ÿé‡å­ç›¸ä½ï¼‰
            phase = self.calculate_global_phase(psi)
            phase_history.append(phase)
            
            # å‘¨æœŸæ€§æ³¨å…¥33ç›¸å…³æ‰°åŠ¨
            if t % 33 == 0:
                # åœ¨33å€æ•°æ—¶é—´æ­¥æ–½åŠ ç‰¹æ®Šæ‰°åŠ¨
                psi = self.apply_33_perturbation(psi, t)
        
        return np.array(fidelity_history), np.array(phase_history)
    
    def create_max_entangled_state(self):
        """åˆ›å»ºæœ€å¤§çº ç¼ æ€"""
        state = np.zeros(self.dim, dtype=complex)
        # GHZæ€: (|00...0> + |11...1>) / sqrt(2)
        state[0] = 1/np.sqrt(2)
        state[-1] = 1/np.sqrt(2)
        return state
    
    def apply_decoherence(self, state, decoherence_param):
        """åº”ç”¨é€€ç›¸å¹²å™ªå£°"""
        # ç›¸ä½é˜»å°¼ä¿¡é“
        prob = 1 - np.exp(-decoherence_param)
        
        # éšæœºç›¸ä½ç¿»è½¬
        if random.random() < prob:
            # åœ¨33ç›¸å…³ä½ç½®æœ‰æ›´å¼ºçš„æ•ˆåº”
            flip_strength = 0.1 + 0.05 * (decoherence_param % 33) / 33
            phase_flip = np.exp(1j * flip_strength * np.pi)
            state = state * phase_flip
        
        # å½’ä¸€åŒ–
        norm = np.linalg.norm(state)
        if norm > 0:
            state = state / norm
            
        return state
    
    def apply_33_perturbation(self, state, t):
        """åœ¨33å€æ•°æ—¶é—´æ­¥æ–½åŠ ç‰¹æ®Šæ‰°åŠ¨"""
        # æ‰°åŠ¨å¼ºåº¦ä¸33å‘¨æœŸç›¸å…³
        perturbation_strength = 0.05 * (1 + np.sin(2 * np.pi * t / 33))
        
        # åˆ›å»ºéšæœºå¹ºæ­£æ‰°åŠ¨
        perturbation = self.random_unitary(perturbation_strength)
        
        # åº”ç”¨æ‰°åŠ¨
        state = perturbation @ state
        
        return state
    
    def random_unitary(self, strength):
        """ç”Ÿæˆéšæœºå¹ºæ­£çŸ©é˜µ"""
        # ä½¿ç”¨33ç›¸å…³çš„éšæœºç§å­
        np.random.seed(int(time.time() * 1000) % 33)
        
        # ç”Ÿæˆéšæœºå„ç±³çŸ©é˜µ
        H = np.random.randn(self.dim, self.dim) + 1j * np.random.randn(self.dim, self.dim)
        H = (H + H.conj().T) / 2
        
        # æŒ‡æ•°æ˜ å°„å¾—åˆ°å¹ºæ­£çŸ©é˜µ
        U = np.linalg.matrix_exp(1j * strength * H)
        
        return U
    
    def calculate_fidelity(self, state):
        """è®¡ç®—ä¸åˆå§‹æ€çš„ä¿çœŸåº¦"""
        initial_state = self.create_max_entangled_state()
        fid = np.abs(np.vdot(initial_state, state)) ** 2
        return fid
    
    def calculate_global_phase(self, state):
        """è®¡ç®—å…¨å±€ç›¸ä½"""
        # æå–ç›¸ä½ä¿¡æ¯
        phase = np.angle(state[0])
        return phase

class PeriodicityAnalyzer:
    """åˆ†ææ—¶é—´åºåˆ—ä¸­çš„33å‘¨æœŸ"""
    
    def __init__(self, signal_data):
        self.signal = signal_data
        self.n = len(signal_data)
        
    def fft_analysis(self):
        """FFTåˆ†æå¯»æ‰¾ä¸»å¯¼é¢‘ç‡"""
        # å»è¶‹åŠ¿
        signal_detrended = signal.detrend(self.signal)
        
        # è®¡ç®—FFT
        yf = fft(signal_detrended)
        xf = fftfreq(self.n, 1)
        
        # åªå–æ­£é¢‘ç‡
        pos_mask = xf > 0
        xf_pos = xf[pos_mask]
        yf_pos = np.abs(yf[pos_mask])
        
        return xf_pos, yf_pos
    
    def find_33_period(self):
        """ä¸“é—¨æ£€æµ‹33å‘¨æœŸ"""
        # è®¡ç®—è‡ªç›¸å…³
        autocorr = np.correlate(self.signal, self.signal, mode='full')
        autocorr = autocorr[autocorr.size // 2:]  # å–ä¸€åŠ
        
        # å¯»æ‰¾33é™„è¿‘çš„å³°å€¼
        search_radius = 3
        target_period = 33
        
        max_corr = 0
        best_period = 0
        
        for period in range(target_period - search_radius, target_period + search_radius + 1):
            if 0 < period < len(autocorr):
                corr_value = autocorr[period]
                if corr_value > max_corr:
                    max_corr = corr_value
                    best_period = period
        
        # è®¡ç®—æ˜¾è‘—æ€§
        significance = self.calculate_significance(best_period)
        
        return best_period, max_corr, significance
    
    def calculate_significance(self, period):
        """è®¡ç®—33å‘¨æœŸçš„ç»Ÿè®¡æ˜¾è‘—æ€§"""
        if period <= 0:
            return 0
        
        # ç”Ÿæˆéšæœºåºåˆ—å¯¹æ¯”
        random_signals = []
        for _ in range(1000):
            random_signal = np.random.randn(self.n)
            random_corr = np.correlate(random_signal, random_signal, mode='full')
            random_corr = random_corr[random_corr.size // 2:]
            
            if period < len(random_corr):
                random_signals.append(random_corr[period])
        
        # è®¡ç®—å®é™…ä¿¡å·çš„ç›¸å…³æ€§
        autocorr = np.correlate(self.signal, self.signal, mode='full')
        autocorr = autocorr[autocorr.size // 2:]
        
        if period >= len(autocorr):
            return 0
        
        actual_corr = autocorr[period]
        
        # è®¡ç®—zåˆ†æ•°
        mean_random = np.mean(random_signals)
        std_random = np.std(random_signals)
        
        if std_random > 0:
            z_score = (actual_corr - mean_random) / std_random
        else:
            z_score = 0
        
        return z_score
    
    def monte_carlo_test(self, n_simulations=10000):
        """è’™ç‰¹å¡æ´›æµ‹è¯•ï¼šéšæœºåºåˆ—ä¸­å‡ºç°ç±»ä¼¼33å‘¨æœŸçš„æ¦‚ç‡"""
        print(f"æ‰§è¡Œè’™ç‰¹å¡æ´›æµ‹è¯• ({n_simulations} æ¬¡æ¨¡æ‹Ÿ)...")
        
        # å­˜å‚¨æ¯æ¬¡æ¨¡æ‹Ÿçš„æœ€å¤§ç›¸å…³æ€§
        max_correlations = []
        
        for i in range(n_simulations):
            if i % 1000 == 0:
                print(f"  è¿›åº¦: {i}/{n_simulations}")
            
            # ç”Ÿæˆéšæœºä¿¡å·
            random_signal = np.random.randn(self.n)
            
            # è®¡ç®—è‡ªç›¸å…³
            autocorr = np.correlate(random_signal, random_signal, mode='full')
            autocorr = autocorr[autocorr.size // 2:]
            
            # åœ¨33é™„è¿‘æ‰¾æœ€å¤§ç›¸å…³
            search_range = range(30, 37)  # 33Â±3
            max_corr = 0
            for lag in search_range:
                if lag < len(autocorr):
                    max_corr = max(max_corr, autocorr[lag])
            
            max_correlations.append(max_corr)
        
        # è®¡ç®—å®é™…ä¿¡å·çš„33å‘¨æœŸç›¸å…³æ€§
        actual_autocorr = np.correlate(self.signal, self.signal, mode='full')
        actual_autocorr = actual_autocorr[actual_autocorr.size // 2:]
        
        actual_corr_33 = 0
        for lag in range(30, 37):
            if lag < len(actual_autocorr):
                actual_corr_33 = max(actual_corr_33, actual_autocorr[lag])
        
        # è®¡ç®—på€¼
        count_exceeding = sum(1 for corr in max_correlations if corr >= actual_corr_33)
        p_value = count_exceeding / n_simulations
        
        return p_value, actual_corr_33, np.mean(max_correlations)

def run_quantum_verification():
    """è¿è¡Œé‡å­è®¡ç®—33å‘¨æœŸéªŒè¯"""
    print("=" * 70)
    print("å®éªŒ1ï¼šé‡å­è®¡ç®—é€€ç›¸å¹²ä¸­çš„33å‘¨æœŸæ£€æµ‹")
    print("=" * 70)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # 1. æ¨¡æ‹Ÿé‡å­é€€ç›¸å¹²
    print("æ­¥éª¤1: æ¨¡æ‹Ÿé‡å­é€€ç›¸å¹²è¿‡ç¨‹...")
    simulator = QuantumDecoherenceSimulator(n_qubits=4, n_steps=330)  # 33*10
    fidelity_history, phase_history = simulator.simulate_decoherence(coherence_time=33)
    
    print(f"  ç”Ÿæˆé•¿åº¦ {len(fidelity_history)} çš„æ—¶é—´åºåˆ—")
    print(f"  æœ€ç»ˆä¿çœŸåº¦: {fidelity_history[-1]:.6f}")
    print(f"  ä¿çœŸåº¦èŒƒå›´: [{fidelity_history.min():.6f}, {fidelity_history.max():.6f}]")
    
    # 2. åˆ†æ33å‘¨æœŸ
    print("\næ­¥éª¤2: åˆ†æ33å‘¨æœŸæ¨¡å¼...")
    analyzer = PeriodicityAnalyzer(fidelity_history)
    
    # FFTåˆ†æ
    xf, yf = analyzer.fft_analysis()
    
    # å¯»æ‰¾33å‘¨æœŸ
    period_33, corr_33, significance = analyzer.find_33_period()
    
    print(f"  æ£€æµ‹åˆ°ä¸»å¯¼å‘¨æœŸ: {period_33}")
    print(f"  33å‘¨æœŸç›¸å…³æ€§: {corr_33:.6f}")
    print(f"  33å‘¨æœŸæ˜¾è‘—æ€§(zåˆ†æ•°): {significance:.3f}")
    
    # 3. è’™ç‰¹å¡æ´›æµ‹è¯•
    print("\næ­¥éª¤3: æ‰§è¡Œè’™ç‰¹å¡æ´›æ˜¾è‘—æ€§æµ‹è¯•...")
    p_value, actual_corr, random_mean = analyzer.monte_carlo_test(n_simulations=10000)
    
    print(f"  å®é™…33å‘¨æœŸç›¸å…³æ€§: {actual_corr:.6f}")
    print(f"  éšæœºåºåˆ—å¹³å‡ç›¸å…³æ€§: {random_mean:.6f}")
    print(f"  på€¼: {p_value:.6f}")
    print(f"  ç›¸å½“äº: 1/{int(1/p_value) if p_value>0 else 'âˆ'}")
    
    # 4. æ£€æŸ¥33å€æ•°ä½ç½®çš„ä¿çœŸåº¦æ¨¡å¼
    print("\næ­¥éª¤4: åˆ†æ33å€æ•°ä½ç½®çš„ç³»ç»Ÿæ€§å·®å¼‚...")
    
    # åˆ†ç»„ï¼š33å€æ•°ä½ç½® vs å…¶ä»–ä½ç½®
    positions_33 = [i for i in range(len(fidelity_history)) if i % 33 == 0]
    positions_other = [i for i in range(len(fidelity_history)) if i % 33 != 0]
    
    values_33 = [fidelity_history[i] for i in positions_33 if i < len(fidelity_history)]
    values_other = [fidelity_history[i] for i in positions_other if i < len(fidelity_history)]
    
    if values_33 and values_other:
        mean_33 = np.mean(values_33)
        mean_other = np.mean(values_other)
        std_33 = np.std(values_33)
        std_other = np.std(values_other)
        
        # tæ£€éªŒï¼ˆç®€åŒ–ç‰ˆï¼‰
        n1, n2 = len(values_33), len(values_other)
        pooled_se = np.sqrt((std_33**2)/n1 + (std_other**2)/n2)
        
        if pooled_se > 0:
            t_value = abs(mean_33 - mean_other) / pooled_se
        else:
            t_value = 0
        
        print(f"  33å€æ•°ä½ç½®å¹³å‡ä¿çœŸåº¦: {mean_33:.6f} (n={n1})")
        print(f"  å…¶ä»–ä½ç½®å¹³å‡ä¿çœŸåº¦: {mean_other:.6f} (n={n2})")
        print(f"  å·®å¼‚: {abs(mean_33-mean_other)/mean_other*100:.2f}%")
        print(f"  tç»Ÿè®¡é‡: {t_value:.3f}")
    
    # 5. ç”Ÿæˆå¯è§†åŒ–
    print("\næ­¥éª¤5: ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    generate_plots(fidelity_history, phase_history, xf, yf, period_33)
    
    # 6. ç»“è®º
    print("\n" + "=" * 70)
    print("å®éªŒç»“è®º:")
    print("=" * 70)
    
    criteria_passed = 0
    total_criteria = 3
    
    # æ ‡å‡†1: på€¼ < 0.001
    if p_value < 0.001:
        print("âœ… æ ‡å‡†1: på€¼ < 0.001 (å®é™…: {:.6f})".format(p_value))
        criteria_passed += 1
    else:
        print("âš ï¸  æ ‡å‡†1: på€¼ >= 0.001 (å®é™…: {:.6f})".format(p_value))
    
    # æ ‡å‡†2: 33å‘¨æœŸç›¸å…³æ€§ > éšæœºå¹³å‡çš„3å€
    if actual_corr > random_mean * 3:
        print("âœ… æ ‡å‡†2: 33å‘¨æœŸç›¸å…³æ€§ > éšæœºå¹³å‡3å€")
        criteria_passed += 1
    else:
        print("âš ï¸  æ ‡å‡†2: 33å‘¨æœŸç›¸å…³æ€§ä¸è¶³")
    
    # æ ‡å‡†3: zåˆ†æ•° > 3
    if significance > 3:
        print("âœ… æ ‡å‡†3: 33å‘¨æœŸæ˜¾è‘—æ€§(zåˆ†æ•° > 3)")
        criteria_passed += 1
    else:
        print("âš ï¸  æ ‡å‡†3: 33å‘¨æœŸæ˜¾è‘—æ€§ä¸è¶³ (z={:.2f})".format(significance))
    
    print(f"\né€šè¿‡æ ‡å‡†: {criteria_passed}/{total_criteria}")
    
    if criteria_passed >= 2:
        print("\nğŸ¯ ç»“è®º: é‡å­é€€ç›¸å¹²ä¸­æ£€æµ‹åˆ°æ˜¾è‘—çš„33å‘¨æœŸæ¨¡å¼")
        print("     æ”¯æŒç‰¹é‡Œè¾¾ç†è®ºçš„33æ­¥é€»è¾‘è‡ªæ•‘æ¡†æ¶")
        return True
    else:
        print("\nâš ï¸  ç»“è®º: 33å‘¨æœŸæ¨¡å¼ä¸æ˜¾è‘—")
        print("     å¯èƒ½éœ€è¦æ›´ç²¾ç¡®çš„é‡å­æ¨¡æ‹Ÿ")
        return False

def generate_plots(fidelity, phase, fft_freq, fft_power, period_33):
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    
    # 1. ä¿çœŸåº¦éšæ—¶é—´å˜åŒ–
    ax1 = axes[0, 0]
    ax1.plot(fidelity, 'b-', linewidth=0.8)
    ax1.set_xlabel('æ—¶é—´æ­¥')
    ax1.set_ylabel('é‡å­æ€ä¿çœŸåº¦')
    ax1.set_title('é‡å­é€€ç›¸å¹²è¿‡ç¨‹')
    ax1.grid(True, alpha=0.3)
    
    # æ ‡è®°33å€æ•°ä½ç½®
    positions_33 = [i for i in range(len(fidelity)) if i % 33 == 0]
    ax1.scatter(positions_33, [fidelity[i] for i in positions_33 if i < len(fidelity)], 
                color='red', s=20, zorder=5, label='33å€æ•°æ­¥')
    ax1.legend()
    
    # 2. ç›¸ä½éšæ—¶é—´å˜åŒ–
    ax2 = axes[0, 1]
    ax2.plot(phase, 'g-', linewidth=0.8)
    ax2.set_xlabel('æ—¶é—´æ­¥')
    ax2.set_ylabel('å…¨å±€ç›¸ä½ (å¼§åº¦)')
    ax2.set_title('é‡å­ç›¸ä½æ¼”åŒ–')
    ax2.grid(True, alpha=0.3)
    
    # 3. FFTé¢‘è°±
    ax3 = axes[1, 0]
    ax3.plot(fft_freq[:50], fft_power[:50], 'r-', linewidth=1.5)
    ax3.set_xlabel('é¢‘ç‡')
    ax3.set_ylabel('åŠŸç‡')
    ax3.set_title('FFTé¢‘è°±åˆ†æ')
    ax3.grid(True, alpha=0.3)
    
    # æ ‡è®°33ç›¸å…³é¢‘ç‡
    freq_33 = 1/33 if 1/33 < max(fft_freq[:50]) else 0
    if freq_33 > 0:
        idx = np.argmin(np.abs(fft_freq[:50] - freq_33))
        ax3.scatter(fft_freq[idx], fft_power[idx], color='blue', s=50, zorder=5, 
                   label=f'33å‘¨æœŸé¢‘ç‡ ({freq_33:.3f})')
        ax3.legend()
    
    # 4. è‡ªç›¸å…³å‡½æ•°
    ax4 = axes[1, 1]
    autocorr = np.correlate(fidelity, fidelity, mode='full')
    autocorr = autocorr[autocorr.size // 2:]
    ax4.plot(autocorr[:100], 'purple', linewidth=1.5)
    ax4.set_xlabel('å»¶è¿Ÿ (æ—¶é—´æ­¥)')
    ax4.set_ylabel('è‡ªç›¸å…³')
    ax4.set_title('è‡ªç›¸å…³å‡½æ•°')
    ax4.grid(True, alpha=0.3)
    
    # æ ‡è®°33å»¶è¿Ÿ
    if period_33 < len(autocorr):
        ax4.scatter(period_33, autocorr[period_33], color='orange', s=50, zorder=5,
                   label=f'33å»¶è¿Ÿ (corr={autocorr[period_33]:.3f})')
        ax4.legend()
    
    plt.tight_layout()
    plt.savefig('quantum_33_periodicity.png', dpi=150, bbox_inches='tight')
    print("  å›¾è¡¨å·²ä¿å­˜: quantum_33_periodicity.png")
    plt.close()

if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­ï¼ˆå¯é€‰ï¼Œç”¨äºå¯é‡å¤æ€§ï¼‰
    np.random.seed(33)  # ä½¿ç”¨33ä½œä¸ºç§å­
    
    # è¿è¡ŒéªŒè¯
    result = run_quantum_verification()
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    with open('quantum_experiment_result.txt', 'w') as f:
        f.write(f"å®éªŒå®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ç»“æœ: {'é˜³æ€§' if result else 'é˜´æ€§'}\n")
    
    print(f"\nè¯¦ç»†ç»“æœä¿å­˜è‡³: quantum_experiment_result.txt")
